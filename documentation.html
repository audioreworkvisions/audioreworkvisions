<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AUDIOREWORKVISIONS - Dokumentation</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        body {
            background-color: #1c1c1c;
            color: #f1f1f1;
            font-family: Arial, sans-serif;
        }
        header {
            text-align: center;
            padding: 20px;
            position: relative;
        }
        header img {
            width: 200px;
            height: auto;
        }
        header h1 {
            font-size: 2em;
            margin: 10px 0;
        }
        header p {
            font-size: 1.2em;
            color: #ccc;
        }
        .header-button {
            font-size: 1em;
            cursor: pointer;
            background-color: #444;
            color: white;
            padding: 10px;
            border: none;
            border-radius: 5px;
            margin: 10px;
            transition: background-color 0.3s;
        }
        .header-button:hover {
            background-color: #555;
        }
        main {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 20px;
        }
        .documentation {
            width: 100%;
            max-width: 800px;
            background-color: #333;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
            margin-bottom: 20px;
        }
        .documentation h1, .documentation h2 {
            color: #f1f1f1;
        }
        .documentation p {
            color: #ccc;
        }
    </style>
</head>
<body>
    <header>
        <a href="index.html" class="header-button">Zurück zur Hauptseite</a>
        <img src="https://stflywithai026072919948.blob.core.windows.net/datencloud/audioreworkvisions-textlogo/1.png" alt="Logo">
        <h1>Chloé 2020</h1>
    </header>
    <main>
        <section class="documentation" id="documentation-content">
            <body>

    <h1>Dokumentationen</h1>

    <div class="doc-section">
        <h2>Raspberry Pi Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://www.raspberrypi.org/help/">Raspberry Pi Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die offizielle Dokumentation für Raspberry Pi-Computer und Mikrocontroller bietet umfassende Anleitungen und technische Informationen. Sie umfasst Hardware- und Softwaredokumentation, Konfigurationsanleitungen, Tutorials und vieles mehr.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Einrichtung und Konfiguration:</strong> Anleitung zur Installation des Raspberry Pi OS, Konfiguration der Netzwerkeinstellungen und Verbindung von Peripheriegeräten.</li>
                <li><strong>Fernzugriff:</strong> Anleitungen zur Einrichtung von SSH und VNC für den Fernzugriff auf den Raspberry Pi.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://www.raspberrypi.org/help/">Raspberry Pi Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>Docker Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://docs.docker.com/">Docker Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Umfassende Dokumentation für Docker, die Installation, Konfiguration und Nutzung von Docker-Produkten abdeckt. Sie bietet Leitfäden, Handbücher und Referenzmaterialien zur Containerisierung von Anwendungen und Verwaltung von Docker-Umgebungen.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Docker Einrichtung:</strong> Anleitungen zur Installation von Docker auf verschiedenen Betriebssystemen und Konfiguration von Docker Desktop.</li>
                <li><strong>Verwendung der Docker CLI:</strong> Detaillierte Anleitungen zur Nutzung der Docker-Befehlszeilenschnittstelle zur Verwaltung von Containern, Images, Netzwerken und Volumes.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://docs.docker.com/">Docker Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>Docker Buildx Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://docs.docker.com/buildx/">Docker Buildx Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Docker Buildx erweitert die Funktionen des Docker `docker build` Befehls und bietet erweiterte Funktionen wie Multi-Architektur-Builds, Cache-Management und BuildKit-Integration.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Multi-Architektur-Builds:</strong> Vereinfachung der Erstellung von Docker-Images für mehrere CPU-Architekturen (z. B. ARM und x86) mit einem einzigen Build-Befehl.</li>
                <li><strong>Build-Cache-Export:</strong> Ermöglicht den Export und Import von Build-Caches, um nachfolgende Builds zu beschleunigen und Caches zwischen verschiedenen Umgebungen zu teilen.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://docs.docker.com/buildx/">Docker Buildx Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>FastAPI Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://fastapi.tiangolo.com/">FastAPI Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> FastAPI ist ein modernes, schnelles (hochleistungsfähiges) Webframework für den Aufbau von APIs mit Python, basierend auf Standard-Python-Typ-Hinweisen. Es bietet automatische interaktive Dokumentation, hohe Leistung und einfache Nutzung.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Schneller Aufbau von APIs:</strong> FastAPI ermöglicht es Entwicklern, schnell APIs mit automatischer Dokumentation unter Verwendung von OpenAPI und JSON-Schema-Standards zu erstellen.</li>
                <li><strong>Asynchrones Programmieren:</strong> FastAPI unterstützt asynchrones Programmieren, wodurch die Entwicklung leistungsfähiger Anwendungen ermöglicht wird.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://fastapi.tiangolo.com/">FastAPI Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>Ubuntu Server Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://ubuntu.com/server/docs">Ubuntu Server Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die Ubuntu Server Dokumentation bietet umfassende Anleitungen zur Installation, Konfiguration und Verwaltung von Ubuntu Server. Sie deckt Themen wie Netzwerkkonfiguration, Paketverwaltung, Sicherheitspraktiken und Virtualisierung ab.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Server-Installation:</strong> Detaillierte Anleitungen zur Installation von Ubuntu Server, einschließlich der Erstellung von bootfähigen Medien und der Partitionierung von Festplatten.</li>
                <li><strong>Netzwerkkonfiguration:</strong> Leitfäden zur Konfiguration von Netzwerkeinstellungen mit Netplan, Einrichtung von DHCP und Integration in Active Directory.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://ubuntu.com/server/docs">Ubuntu Server Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>NGINX Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://nginx.org/en/docs/">NGINX Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die offizielle Dokumentation für NGINX bietet umfassende Informationen zur Installation, Konfiguration und Bereitstellung von NGINX als Webserver, Reverse Proxy und Load Balancer. Sie enthält ausführliche Leitfäden und Referenzen zu verschiedenen NGINX-Funktionen und -Modulen.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Einrichtung eines einfachen HTTP-Servers:</strong> Detaillierte Anleitungen zur Konfiguration von NGINX zur Bereitstellung statischer Inhalte und zum Proxying von Anfragen an Backend-Server.</li>
                <li><strong>HTTPS-Konfiguration:</strong> Leitfäden zur Einrichtung sicherer HTTPS-Server mit SSL/TLS, einschließlich Zertifikatkonfiguration und SSL-Parametern.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://nginx.org/en/docs/">NGINX Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>React Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://react.dev/">React Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die offizielle Dokumentation für React, eine JavaScript-Bibliothek zum Aufbau von Benutzeroberflächen. Sie bietet umfassende Leitfäden, Tutorials und Referenzen zu React-Komponenten, Hooks und APIs.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Erstellung interaktiver Benutzeroberflächen:</strong> React ermöglicht es Entwicklern, wiederverwendbare UI-Komponenten zu erstellen, was den Aufbau komplexer Schnittstellen aus einfachen, isolierten Teilen erleichtert.</li>
                <li><strong>Zustands- und Nebenwirkungsmanagement:</strong> React Hooks, wie `useState` und `useEffect`, bieten eine leistungsstarke Möglichkeit, den Zustand von Komponenten zu verwalten und Nebenwirkungen in funktionalen Komponenten zu behandeln.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://react.dev/">React Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>Node.js Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://nodejs.org/en/docs/">Node.js Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die offizielle Dokumentation für Node.js, eine JavaScript-Laufzeitumgebung, die auf der V8-JavaScript-Engine von Chrome basiert. Sie bietet umfassende Leitfäden und Referenzen zu Node.js APIs, einschließlich Module, asynchroner Programmierung, Dateiverwaltung und mehr.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Erstellung von Webservern:</strong> Node.js ermöglicht es Entwicklern, leistungsfähige Webserver mit einfachem JavaScript-Code zu erstellen.</li>
                <li><strong>Asynchrone Programmierung:</strong> Node.js bietet eine Reihe von asynchronen I/O-Primitiven, was es ideal für Anwendungen macht, die nicht-blockierende Operationen erfordern.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://nodejs.org/en/docs/">Node.js Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>npm Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://docs.npmjs.com/">npm Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die offizielle Dokumentation für npm, den Paketmanager für Node.js. Sie bietet umfassende Leitfäden und Referenzen zur Nutzung von npm zur Verwaltung von JavaScript-Paketen, einschließlich Installation, Konfiguration und Veröffentlichung.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Installation von Paketen:</strong> npm ermöglicht es Entwicklern, Pakete aus dem npm-Registry zu installieren und in ihren Projekten zu verwenden, einschließlich Optionen für lokale und globale Installationen.</li>
                <li><strong>Veröffentlichung von Paketen:</strong> npm bietet Werkzeuge, mit denen Entwickler ihre eigenen Pakete im npm-Registry veröffentlichen können, um sie anderen zur Verfügung zu stellen und Beiträge zu ermöglichen.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://docs.npmjs.com/">npm Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>GPIO Pinout Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://www.raspberrypi.org/documentation/usage/gpio/">GPIO Pinout Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Diese Dokumentation bietet detaillierte Informationen zu den General-Purpose Input/Output (GPIO) Pins der Raspberry Pi Boards. Sie umfasst die Funktionen der Pins, Spannungspegel und wie diese Pins in verschiedenen Projekten konfiguriert und verwendet werden können.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Steuerung von LEDs:</strong> Verwendung der GPIO-Pins zur Steuerung des Ein- und Ausschaltzustands von LEDs in verschiedenen Mustern.</li>
                <li><strong>Auslesen von Sensordaten:</strong> Anschluss von Sensoren wie Temperatur- oder Bewegungssensoren an die GPIO-Pins, um Daten auszulesen und in Anwendungen zu verwenden.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://www.raspberrypi.org/documentation/usage/gpio/">GPIO Pinout Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>Adafruit SSD1306 Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://learn.adafruit.com/monochrome-oled-breakouts/arduino-library-and-examples">Adafruit SSD1306 Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Diese Dokumentation behandelt die Verwendung der monochromen OLED-Displays von Adafruit, die auf dem SSD1306-Controller basieren, mit Arduino, CircuitPython und MicroPython. Sie enthält Anleitungen zur Einrichtung, Code-Beispiele und Anleitungen zum Zeichnen von Grafiken und Texten auf den Displays.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Anzeige von Sensordaten:</strong> Verwendung des SSD1306 OLED zur Anzeige von Echtzeitdaten von verschiedenen Sensoren in einem klaren, lesbaren Format.</li>
                <li><strong>Erstellung einfacher GUIs:</strong> Aufbau grafischer Benutzeroberflächen für eingebettete Projekte, wie die Anzeige von Statusmeldungen oder Systeminformationen.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://learn.adafruit.com/monochrome-oled-breakouts/arduino-library-and-examples">Adafruit SSD1306 Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>pyttsx3 Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://pyttsx3.readthedocs.io/">pyttsx3 Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die pyttsx3-Bibliothek bietet Text-to-Speech-Funktionen in Python. Sie arbeitet offline und ist mit mehreren Sprachsynthesemotoren kompatibel, einschließlich SAPI5 auf Windows, NSSpeechSynthesizer auf macOS und espeak auf Linux. Die Bibliothek ermöglicht die Anpassung von Stimmeigenschaften, ereignisgesteuerte Benachrichtigungen und die Integration in verschiedene Anwendungen.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Sprachbenachrichtigungen:</strong> Implementierung von Text-to-Speech-Benachrichtigungen in Anwendungen, wie Alarmsystemen oder assistiven Technologien.</li>
                <li><strong>Erstellung von Hörbüchern:</strong> Konvertierung von Textdokumenten in Sprache, um Hörbücher oder gesprochene Inhalte für sehbehinderte Benutzer zu erstellen.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://pyttsx3.readthedocs.io/">pyttsx3 Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>I2C Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://learn.adafruit.com/working-with-i2c-devices">I2C Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Diese Dokumentation bietet einen Überblick über das Inter-Integrated Circuit (I2C) Protokoll, eine beliebte Methode zum Anschließen von Peripheriegeräten wie Sensoren an einen Host-Controller. Sie behandelt die Grundlagen der I2C-Kommunikation, einschließlich Datenübertragung, Geräteadressierung und häufig auftretender Probleme.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Anschluss von Sensoren an Mikrocontroller:</strong> Verwendung von I2C zur Verbindung mehrerer Sensoren mit einem einzigen Mikrocontroller, wodurch eine effiziente Datenerfassung mit minimaler Verkabelung ermöglicht wird.</li>
                <li><strong>Fehlerbehebung bei I2C-Geräten:</strong> Lernen, wie man I2C-Adressen scannt und erkennt, häufige Probleme behebt und eine ordnungsgemäße Kommunikation zwischen Geräten sicherstellt.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://learn.adafruit.com/working-with-i2c-devices">I2C Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>ALSA Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://www.alsa-project.org/main/index.php/Documentation">ALSA Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> Die Advanced Linux Sound Architecture (ALSA) bietet Audio- und MIDI-Funktionalität für das Linux-Betriebssystem. Sie umfasst Funktionen wie effiziente Unterstützung für alle Arten von Audio-Schnittstellen, modularisierte Soundtreiber und Kompatibilität mit der älteren Open Sound System (OSS) API. Die Dokumentation umfasst Benutzerinformationen, Systemadministrationshandbücher, Entwicklerinformationen und Hardwareunterstützung.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Entwicklung von Audiotreibern:</strong> Umfassende Leitfäden zur Entwicklung von Gerätetreibern für ALSA, einschließlich spezieller Fokus auf PCI-Soundkarten.</li>
                <li><strong>Anwendungsentwicklung:</strong> Nutzung der ALSA-Bibliotheks-API zur nativen ALSA-Unterstützung in Anwendungen, mit Referenzmaterialien und Tutorials.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://www.alsa-project.org/main/index.php/Documentation">ALSA Dokumentation</a></li>
        </ul>
    </div>

    <div class="doc-section">
        <h2>PortAudio Dokumentation</h2>
        <ul>
            <li><strong>Name:</strong> <a href="https://portaudio.com/docs/v19-doxydocs/">PortAudio Dokumentation</a></li>
            <li><strong>Beschreibung:</strong> PortAudio ist eine plattformübergreifende, Open-Source-C-Bibliothek für Echtzeit-Audio-Ein- und Ausgabe. Sie bietet Funktionen, mit denen Software Echtzeit-Audiostreams von den Hardware-Audioschnittstellen eines Computers aufnehmen und ausgeben kann. Die Bibliothek vereinfacht das Schreiben plattformübergreifender Audioanwendungen und das Entwickeln von Audiosoftware, indem sie die Komplexität der direkten Arbeit mit nativen Audio-APIs verbirgt.</li>
            <li><strong>Anwendungsfälle:</strong></li>
            <ul>
                <li><strong>Echtzeit-Audioprozessierung:</strong> Entwickeln von Anwendungen, die Echtzeit-Audio-Ein- und Ausgabe benötigen, wie digitale Audio-Workstations (DAWs) oder Live-Audio-Effektprozessoren.</li>
                <li><strong>Audiostreaming:</strong> Implementierung von Streaming-Diensten oder Anwendungen, die kontinuierliche Audio-Datenströme verarbeiten, wie Internettelefonie oder Musik-Streaming-Dienste.</li>
            </ul>
            <li><strong>Link:</strong> <a href="https://portaudio.com/docs/v19-doxydocs/">PortAudio Dokumentation</a></li>
        </ul>
    </div>

<h3>Sprachsynthese-Dokumentation (Speech Recognition)</h3>
<p>
    <strong>Name:</strong> <a href="https://pypi.org/project">SpeechRecognition Dokumentation</a>
</p>

<h3>Sprachsynthese-Dokumentation</h3>

<h4>pyttsx3 Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://pyttsx3.readthedocs.io/">pyttsx3 Dokumentation</a><br>
    <strong>Beschreibung:</strong> pyttsx3 ist eine plattformübergreifende Text-zu-Sprache-Bibliothek für Python. Sie funktioniert offline und ist mit verschiedenen Sprachsynthesemotoren kompatibel, einschließlich SAPI5 auf Windows, NSSpeechSynthesizer auf macOS und espeak auf Linux. Die Bibliothek ermöglicht die Anpassung von Stimmeigenschaften, ereignisgesteuerte Benachrichtigungen und die Integration in verschiedene Anwendungen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Sprachbenachrichtigungen:</strong> Implementierung von Text-zu-Sprache-Benachrichtigungen in Anwendungen, wie Alarmsystemen oder assistiven Technologien.</li>
    <li><strong>Erstellung von Hörbüchern:</strong> Konvertierung von Textdokumenten in gesprochene Inhalte, um Hörbücher oder Sprachinhalte für sehbehinderte Benutzer zu erstellen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://pyttsx3.readthedocs.io/">pyttsx3 Dokumentation</a>
</p>

<h4>Coqui TTS Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://coqui-tts.readthedocs.io/">Coqui TTS Dokumentation</a><br>
    <strong>Beschreibung:</strong> Coqui TTS ist ein Open-Source-Text-zu-Sprache-Toolkit, das eine CLI-Schnittstelle für die Sprachsynthese mit vortrainierten Modellen bietet. Benutzer können entweder eigene Modelle oder bereitgestellte Modelle verwenden, um Sprache zu synthetisieren. Die Bibliothek unterstützt verschiedene Modelle und Vocoder, einschließlich Multi-Speaker-Modelle und Voice-Conversion-Modelle.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Sprachsynthese:</strong> Erstellung von Audiodateien aus Text mit vortrainierten Modellen, ideal für die Entwicklung von Sprachassistenzsystemen oder interaktiven Anwendungen.</li>
    <li><strong>Stimmenkonvertierung:</strong> Konvertierung der Stimme eines Sprechers in die eines anderen, nützlich für Anwendungen wie personalisierte Sprachassistenten oder stimmgesteuerte Geräte.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://coqui-tts.readthedocs.io/">Coqui TTS Dokumentation</a>
</p>

<h4>gTTS Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://gtts.readthedocs.io/">gTTS Dokumentation</a><br>
    <strong>Beschreibung:</strong> gTTS (Google Text-to-Speech) ist eine Python-Bibliothek und CLI-Tool zur Schnittstelle mit dem Google Text-to-Speech API. Sie ermöglicht die Konvertierung von Text in Sprache unter Verwendung verschiedener Sprach- und Dialektoptionen. gTTS kann Audiodateien direkt erstellen oder Audio in Echtzeit abspielen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Echtzeit-Sprachausgabe:</strong> Entwicklung von Anwendungen, die Text-zu-Sprache-Funktionen in Echtzeit bieten, wie Chatbots oder interaktive Sprachsysteme.</li>
    <li><strong>Erstellung von Sprachaufnahmen:</strong> Erstellen von Sprachaufnahmen für E-Learning, Podcasts oder andere Anwendungen, die Sprachinhalte erfordern.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://gtts.readthedocs.io/">gTTS Dokumentation</a>
</p>

<h4>SpeechRecognition Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://pypi.org/project/SpeechRecognition/">SpeechRecognition Dokumentation</a><br>
    <strong>Beschreibung:</strong> SpeechRecognition ist eine Python-Bibliothek, die eine einfache API für die Sprach-zu-Text-Umwandlung bietet. Sie unterstützt mehrere Spracherkennungssysteme wie Google Web Speech API, CMU Sphinx, Microsoft Bing Voice Recognition, Houndify API, IBM Speech to Text und andere.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Sprachgesteuerte Anwendungen:</strong> Entwickeln von Anwendungen, die durch Sprachbefehle gesteuert werden, wie persönliche Assistenten oder Smart-Home-Geräte.</li>
    <li><strong>Transkription von Audiodaten:</strong> Automatisches Transkribieren von Audiodateien in Text, ideal für die Erstellung von Meetingprotokollen oder Diktaten.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://pypi.org/project/SpeechRecognition/">SpeechRecognition Dokumentation</a>
</p>

<h4>Mozilla DeepSpeech Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://deepspeech.readthedocs.io/">DeepSpeech Dokumentation</a><br>
    <strong>Beschreibung:</strong> Mozilla DeepSpeech ist eine Open-Source-Spracherkennungs-Engine, die auf neuronalen Netzwerken basiert. Sie ist darauf ausgelegt, effizient auf vielen Plattformen zu laufen und unterstützt verschiedene Programmiersprachen. DeepSpeech bietet eine einfache Möglichkeit, Sprache in Text umzuwandeln und kann sowohl offline als auch online genutzt werden.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Spracherkennung in Anwendungen:</strong> Integration von DeepSpeech in mobile oder Desktop-Anwendungen zur Sprach-zu-Text-Umwandlung.</li>
    <li><strong>Transkription großer Audiodatenmengen:</strong> Verwendung von DeepSpeech zur Transkription großer Mengen von Audiodaten, wie Interviews oder Podcasts.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://deepspeech.readthedocs.io/">DeepSpeech Dokumentation</a>
</p>

<h4>SpeechBrain Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://speechbrain.readthedocs.io/">SpeechBrain Dokumentation</a><br>
    <strong>Beschreibung:</strong> SpeechBrain ist ein All-in-One-Toolkit für Sprachtechnologien, das auf PyTorch basiert. Es unterstützt die Entwicklung von Sprach-zu-Text-, Sprechererkennungs-, Sprachverbesserungs- und anderen Sprachverarbeitungssystemen. SpeechBrain bietet eine umfangreiche Sammlung vortrainierter Modelle und eine benutzerfreundliche API.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Automatische Spracherkennung (ASR):</strong> Entwicklung und Training von ASR-Modellen zur Umwandlung von gesprochener Sprache in Text.</li>
    <li><strong>Sprechererkennung:</strong> Implementierung von Systemen zur Identifizierung oder Verifizierung von Sprechern basierend auf ihren Stimmmerkmalen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://speechbrain.readthedocs.io/">SpeechBrain Dokumentation</a>
</p>

<h4>Flash SpeechRecognition Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://lightning-flash.readthedocs.io/en/latest/tasks/speech_recognition.html">Flash SpeechRecognition Dokumentation</a><br>
    <strong>Beschreibung:</strong> Flash SpeechRecognition ist eine Erweiterung von PyTorch Lightning, die die Entwicklung und Bereitstellung von Sprach-zu-Text-Modellen erleichtert. Es integriert verschiedene vortrainierte Modelle wie Wav2Vec2, die für die Sprachumwandlung verwendet werden können. Die Bibliothek ermöglicht einfache Feinabstimmung, Vorhersage und Bereitstellung von Sprachmodellen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Feinabstimmung von Modellen:</strong> Verwenden Sie Flash SpeechRecognition, um vortrainierte Sprachmodelle mit eigenen Daten zu verfeinern und die Genauigkeit für spezifische Anwendungsfälle zu verbessern.</li>
    <li><strong>Echtzeit-Spracherkennung:</strong> Implementierung von Echtzeit-Spracherkennungssystemen in Anwendungen zur Transkription von Sprache in Text.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://lightning-flash.readthedocs.io/en/latest/tasks/speech_recognition.html">Flash SpeechRecognition Dokumentation</a>
</p>

<p>Diese Dokumentationen bieten umfassende Informationen und Beispiele zur Implementierung und Nutzung der jeweiligen Sprachsynthese- und Spracherkennungstechnologien in Python.</p>

<h3>Dokumentation zur Spracherkennung</h3>
<p>
    <strong>Name:</strong> <a href="https://speechrecognition.readthedocs.io/">SpeechRecognition Documentation</a><br>
    <strong>Beschreibung:</strong> Die SpeechRecognition-Bibliothek bietet eine einfache API für die Spracherkennung in Python. Sie unterstützt verschiedene Spracherkennungssysteme wie Google Web Speech API, CMU Sphinx, Microsoft Bing Voice Recognition, Houndify API, IBM Speech to Text und mehr.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Sprachgesteuerte Anwendungen:</strong> Entwicklung von Anwendungen, die durch Sprachbefehle gesteuert werden können, wie persönliche Assistenten oder intelligente Haussteuerungen.</li>
    <li><strong>Transkription von Audioaufnahmen:</strong> Automatische Transkription von Audioaufnahmen in Text, z.B. für Meeting-Protokolle oder Diktate.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://speechrecognition.readthedocs.io/">SpeechRecognition Documentation</a>
</p>

<h3>OpenAI API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://platform.openai.com/docs/api-reference">OpenAI API Dokumentation</a><br>
    <strong>Beschreibung:</strong> Die OpenAI API bietet Zugriff auf fortschrittliche Sprachmodelle wie GPT-4 und GPT-3.5, die es Entwicklern ermöglichen, KI-Funktionen in ihre Anwendungen zu integrieren. Sie unterstützt eine breite Palette von Funktionen wie Textgenerierung, Sprachübersetzung, Zusammenfassungen und mehr.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Textgenerierung:</strong> Erstellen menschenähnlicher Texte für Chatbots, Inhaltserstellung und Kundensupport-Automatisierung.</li>
    <li><strong>Funktionsaufrufe:</strong> Erweiterung von Anwendungen mit strukturierten Ausgaben, die Aufgaben wie API-Aufrufe, Datenbankabfragen oder das Ausführen vordefinierter Funktionen basierend auf natürlicher Sprache ermöglichen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://platform.openai.com/docs/api-reference">OpenAI API Dokumentation</a>
</p>

<h3>CalDAV API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://datatracker.ietf.org/doc/html/rfc4791">CalDAV API Dokumentation</a><br>
    <strong>Beschreibung:</strong> CalDAV ist ein Standardprotokoll, das WebDAV erweitert, um den Zugriff auf Kalender zu ermöglichen. Es erlaubt Clients, auf Kalenderressourcen auf einem Server zuzugreifen, diese zu verwalten und zu teilen, und bietet eine Möglichkeit, Planungsoperationen mit iCalendar-Daten durchzuführen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Kalenderfreigabe und -verwaltung:</strong> Ermöglicht das Teilen und Verwalten von Kalendereinträgen zwischen verschiedenen Clients und Benutzern.</li>
    <li><strong>Automatisierte Termin:</strong></li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://datatracker.ietf.org/doc/html/rfc4791">CalDAV API Dokumentation</a>
</p>

<h3>LiteLLM Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://guidance.readthedocs.io/en/latest/generated/guidance.models.LiteLLM.html">LiteLLM Dokumentation</a><br>
    <strong>Beschreibung:</strong> LiteLLM ist eine leichtgewichtige Modell-API, die für die effiziente Interaktion mit verschiedenen Sprachmodellen entwickelt wurde. Sie vereinfacht die Erstellung und Verwaltung von Modellinstanzen und erleichtert die Integration und Bereitstellung von Sprachmodellen in Anwendungen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Modellverwaltung:</strong> Erstellen, Ändern und Verwalten von Instanzen von Sprachmodellen mit Leichtigkeit, einschließlich der Einstellung von Attributen und der Handhabung des Zustands.</li>
    <li><strong>Interaktive KI-Anwendungen:</strong> Aufbau interaktiver Anwendungen, die Echtzeit-Antworten und Modellaktualisierungen erfordern.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://guidance.readthedocs.io/en/latest/generated/guidance.models.LiteLLM.html">LiteLLM Dokumentation</a>
</p>

<h3>Spotify API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://developer.spotify.com/documentation/web-api/">Spotify API Dokumentation</a><br>
    <strong>Beschreibung:</strong> Die Spotify Web API ermöglicht Entwicklern den Zugriff auf den Musikkatalog von Spotify, das Verwalten von Benutzer-Playlists und -Bibliotheken sowie die Steuerung der Spotify-Wiedergabe. Sie bietet eine breite Palette von Endpunkten, um Daten zu Tracks, Alben, Künstlern und mehr abzurufen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Musik-Entdeckungsanwendung:</strong> Erstellen einer App, die neue Musik basierend auf dem Hörverlauf und den Lieblingskünstlern der Benutzer empfiehlt.</li>
    <li><strong>Wiedergabesteuerung:</strong> Entwickeln einer Web-App, die es Benutzern ermöglicht, die Spotify-Wiedergabe auf ihren Geräten zu steuern, einschließlich Wiedergabe, Pause und Überspringen von Titeln.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://developer.spotify.com/documentation/web-api/">Spotify API Dokumentation</a>
</p>

<h3>Spotipy Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="http://spoti-py.readthedocs.io/">Spotipy Dokumentation</a><br>
    <strong>Beschreibung:</strong> Spotipy ist eine leichtgewichtige Python-Bibliothek für die Spotify Web API. Sie ermöglicht eine einfache Integration mit der Spotify-API und erlaubt es Entwicklern, mit Spotify-Daten zu interagieren, einschließlich der Suche nach Tracks, Künstlern, Alben und dem Verwalten von Benutzer-Playlists.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Musikdatenabfrage:</strong> Abrufen detaillierter Informationen zu Tracks, Künstlern und Alben, um Anwendungen zu erstellen, die Spotify-Musikdaten anzeigen und analysieren.</li>
    <li><strong>Playlist-Management:</strong> Erstellen, Aktualisieren und Verwalten von Spotify-Playlists programmgesteuert, um benutzerdefinierte Erlebnisse und automatisierte Playlist-Kuration zu ermöglichen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="http://spoti-py.readthedocs.io/">Spotipy Dokumentation</a>
</p>

<h3>Spotifyd Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://github.com/Spotifyd/spotifyd/blob/master/README.md">Spotifyd Dokumentation</a><br>
    <strong>Beschreibung:</strong> Spotifyd ist ein Open-Source-Spotify-Client, der als UNIX-Daemon läuft. Er ist leichtgewichtig und unterstützt mehr Plattformen als der offizielle Client. Spotifyd streamt Musik über das Spotify Connect-Protokoll und erscheint als steuerbares Gerät innerhalb der offiziellen Spotify-Clients.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Integration in Hausautomatisierung:</strong> Nutzung von Spotifyd zur Integration von Spotify-Musikstreaming in ein Hausautomatisierungssystem, das die Steuerung der Wiedergabe über verschiedene Smart-Home-Geräte ermöglicht.</li>
    <li><strong>Headless-Musikstreaming:</strong> Einrichtung von Spotifyd auf einem Raspberry Pi oder einem anderen headless Gerät, um eine dedizierte Musik-Streaming-Box zu erstellen, die von jedem Spotify-Client aus gesteuert werden kann.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://github.com/Spotifyd/spotifyd/blob/master/README.md">Spotifyd Dokumentation</a>
</p>

<h3>Philips Hue API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://developers.meethue.com/new-hue-api/">Philips Hue API Dokumentation</a><br>
    <strong>Beschreibung:</strong> Die Philips Hue API ermöglicht Entwicklern die Erstellung von Anwendungen, die Philips Hue-Beleuchtungssysteme steuern können. Die API unterstützt Funktionen wie dynamische Szenen, Gradient-Entertainment-Technologie und proaktive Statusänderungsereignisse im lokalen Netzwerk. Sie enthält umfassende Leitfäden zum Einstieg, zur Anwendungsentwicklung und eine vollständige API-Referenz.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Integration in Hausautomatisierung:</strong> Entwicklung von Anwendungen, die Philips Hue-Lichter mit anderen Smart-Home-Geräten integrieren, um eine automatisierte Steuerung basierend auf verschiedenen Auslösern zu ermöglichen.</li>
    <li><strong>Erstellung benutzerdefinierter Lichteffekte:</strong> Erstellung benutzerdefinierter Lichtszenen und Effekte, die über eine mobile App oder eine Weboberfläche ausgelöst werden können, um die Benutzererfahrung zu verbessern.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://developers.meethue.com/new-hue-api/">Philips Hue API Dokumentation</a>
</p>

<h3>Philips Hue Python API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://github.com/studioimaginaire/phue">phue</a><br>
    <strong>Beschreibung:</strong> Die `phue` Bibliothek ist eine Python-Bibliothek, die für die Interaktion mit dem Philips Hue Beleuchtungssystem entwickelt wurde. Sie bietet umfassende Funktionen zur Steuerung von Lichtern, Gruppen, Zeitplänen und Szenen und unterstützt sowohl prozedurale als auch objektorientierte Programmieransätze.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Automatisierte Lichtsteuerung:</strong> Entwicklung von Skripten zur Automatisierung der Beleuchtung basierend auf Tageszeit oder Sensoreingaben, um Hausautomatisierungssetups zu verbessern.</li>
    <li><strong>Erstellung benutzerdefinierter Lichtszenen:</strong> Erstellen und Verwalten benutzerdefinierter Lichtszenen und Übergänge für personalisierte Ambiente-Einstellungen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://github.com/studioimaginaire/phue">phue Dokumentation</a>
</p>

<h3>HUESDK Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://github.com/AlexisGomes/huesdk">huesdk</a><br>
    <strong>Beschreibung:</strong> `huesdk` ist ein Python SDK für die Philips Hue API, das eine objektorientierte Struktur bietet, um die Interaktion mit den Hue-Lichtern zu vereinfachen. Es unterstützt die Erkennung, Verbindung und Steuerung von Hue-Lichtern, einschließlich der Einstellung von Farben, Helligkeit und Übergangseffekten.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Licht-Synchronisation:</strong> Synchronisieren von Lichtern mit anderen Hausautomatisierungssystemen oder Multimedia-Erlebnissen für immersive Effekte.</li>
    <li><strong>Batch-Lichtsteuerung:</strong> Effiziente Verwaltung mehrerer Lichter oder Lichtgruppen, die Batch-Operationen für eine nahtlose Steuerung ermöglichen.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://github.com/AlexisGomes/huesdk">huesdk Dokumentation</a>
</p>

<h3>OpenWeatherMap API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://openweathermap.org/api">OpenWeatherMap API Dokumentation</a><br>
    <strong>Beschreibung:</strong> Die OpenWeatherMap API bietet Zugriff auf eine breite Palette von Wetterdaten, einschließlich aktueller Wetterbedingungen, Vorhersagen, historischer Daten und Wetterkarten. Sie unterstützt mehrere Formate wie JSON und XML und bietet verschiedene Endpunkte zum Abrufen spezifischer Wetterinformationen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Wettervorhersageanwendungen:</strong> Integration von Echtzeit-Wetterdaten, stündlichen und täglichen Vorhersagen in Anwendungen, um den Benutzern aktuelle Wetterbedingungen bereitzustellen.</li>
    <li><strong>Klimaforschung:</strong> Nutzung historischer Wetterdaten und statistischer Wetterdaten für die Forschung und Analyse von Klimatrends und -mustern.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://openweathermap.org/api">OpenWeatherMap API Dokumentation</a>
</p>

<h3>Open-Meteo API Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://open-meteo.com/en/docs">Open-Meteo API Dokumentation</a><br>
    <strong>Beschreibung:</strong> Open-Meteo bietet eine kostenlose, hochauflösende Wettervorhersage-API, die genaue Wetterdaten aus mehreren Wettermodellen bereitstellt. Sie umfasst Endpunkte für aktuelle Wetterdaten, Vorhersagen, historische Daten und Klimadaten und ist darauf ausgelegt, einfach und unkompliziert zu integrieren, ohne dass ein API-Schlüssel für die nicht-kommerzielle Nutzung erforderlich ist.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Wettervorhersageanwendungen:</strong> Integration von Echtzeit- und Vorhersage-Wetterdaten in mobile oder Webanwendungen, um den Benutzern detaillierte Wetterinformationen bereitzustellen.</li>
    <li><strong>Klimaforschung und -analyse:</strong> Zugriff auf historische Wetterdaten und langfristige Klimamodelle für wissenschaftliche Forschung und Analyse.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://open-meteo.com/en/docs">Open-Meteo API Dokumentation</a>
</p>

<h3>Python Crontab Dokumentation</h3>

<h4>Schedule Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://schedule.readthedocs.io/">Schedule Dokumentation</a><br>
    <strong>Beschreibung:</strong> Schedule ist eine benutzerfreundliche Python-Bibliothek zur Aufgabenplanung, die es ermöglicht, Python-Funktionen (oder andere Callables) periodisch auszuführen. Sie ist leichtgewichtig und hat keine externen Abhängigkeiten, was sie ideal für einfache Automatisierungsaufgaben macht.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Automatisierung wiederkehrender Aufgaben:</strong> Verwendung von Schedule zur regelmäßigen Ausführung von Aufgaben wie Datensicherungen, Berichtserstellung oder Systemwartung ohne manuelles Eingreifen.</li>
    <li><strong>Aufgabenplanung in Anwendungen:</strong> Integration von Schedule in Anwendungen zur Verwaltung periodischer Aufgaben wie das Senden von Benachrichtigungen oder das Aktualisieren von Daten.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://schedule.readthedocs.io/">Schedule Dokumentation</a>
</p>

<h4>APScheduler Dokumentation</h4>
<p>
    <strong>Name:</strong> <a href="https://apscheduler.readthedocs.io/">APScheduler Dokumentation</a><br>
    <strong>Beschreibung:</strong> APScheduler ist eine Python-Bibliothek, die es ermöglicht, Python-Code zu einem späteren Zeitpunkt auszuführen, entweder einmalig oder periodisch. Sie unterstützt verschiedene Trigger wie Cron-ähnliche Ausdrücke, Intervall- und Datumsauslöser, und bietet eine flexible und erweiterbare Architektur für komplexe Planungsanforderungen.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Komplexe Planungsanforderungen:</strong> APScheduler kann komplexe Zeitpläne verwalten, wie das Ausführen von Aufgaben zu bestimmten Zeiten oder Intervallen, mit Unterstützung für mehrere Trigger und Job-Stores.</li>
    <li><strong>Verteiltes Job-Management:</strong> Verwendung von APScheduler zur Verwaltung und Verteilung von Jobs über mehrere Server, um hohe Verfügbarkeit und Skalierbarkeit zu gewährleisten.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://apscheduler.readthedocs.io/">APScheduler Dokumentation</a>
</p>

<h3>Fritzing Schaltpläne Dokumentation</h3>
<p>
    <strong>Name:</strong> <a href="https://fritzing.org/learning/full_reference">Fritzing Dokumentation</a><br>
    <strong>Beschreibung:</strong> Fritzing ist ein Open-Source-Tool zur elektronischen Designautomatisierung (EDA), das darauf abzielt, Designern, Künstlern und Bastlern zu helfen, Elektronikprojekte zu erstellen, zu dokumentieren und zu teilen. Es bietet eine umfassende Umgebung für die Erstellung von Breadboard-, Schaltplan- und PCB-Layouts.
</p>
<p><strong>Anwendungsfälle:</strong></p>
<ol>
    <li><strong>Dokumentation von Elektronikprojekten:</strong> Verwenden Sie Fritzing, um Ihre Elektronikprototypen und -entwürfe visuell zu dokumentieren und zu teilen, mit detaillierten Breadboard-, Schaltplan- und PCB-Ansichten.</li>
    <li><strong>PCB-Design und -Fertigung:</strong> Entwerfen Sie kundenspezifische Leiterplatten (PCBs) mit der benutzerfreundlichen Oberfläche von Fritzing und exportieren Sie Ihre Designs zur Fertigung mit Diensten wie Fritzing Fab.</li>
</ol>
<p>
    <strong>Link:</strong> <a href="https://fritzing.org/learning/full_reference">Fritzing Dokumentation</a>
</p>

        </section>
    </main>
    <footer>
        <p>&copy;Copyright 2024 AUDIOREWORKVISIONS</p>
        <a href="https://www.linkedin.com/in/audioreworkvisions/" target="_blank" class="contact-button">Kontakt auf LinkedIn</a>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/showdown@2.0.3/dist/showdown.min.js"></script>
    <script src="scripts.js"></script>
</body>
</html>
